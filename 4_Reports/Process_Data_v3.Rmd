---
title: "Process_Data_v3"
author: "czx"
date: "`r Sys.Date()`"
output: html_document
---

# Process Coding
## Loading package
```{r Package, warning = FALSE,message = FALSE}
## 加载必要的 R 包
library(tidyr)
library(dplyr)
library(stringr)
library(effsize)
library(here)
library(pwr)
library(ggplot2)
```

# Read csv (区分公开和未公开) [包含没有Trial记录的]
```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 需要排除的文件夹
exclude_folders <- c("Bukowski_2021_AP", "Golubickis_2021_AP", 
                     "Hobbs_2023_PM", "Mcivor_2020_EJN", 
                     "Orellana-Corrales_2021_EP", "Svensson_2021_PR", 
                     "Wang_2016_EPHPP","Liang_2022_HBM","Hobbs_2021_PM",
                     "Lee_2023_Cognition","Orellana-Corrales_2021_APP",
                     "Kirk_2025_BJP","Svensson_2023_QJEP")

## 过滤掉不需要的文件
data_files <- data_files[!grepl(paste(exclude_folders, collapse = "|"), data_files)]

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    Data <- Data %>%
      filter(RT_ms > 10 & RT_ms < 5000, ACC %in% c(0, 1))  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data.csv", row.names = FALSE)
```

# 论文数量、实验数量、被试数
```{r}
library(dplyr)
library(readr)
library(stringr)

# 读取已处理的数据
data <- read_csv("Processed_Data_for_SDE.csv", show_col_types = FALSE)
#data <- read_csv("Processed_Data.csv", show_col_types = FALSE)

# 处理 Source 变量，提取文章信息（支持两种格式）
data <- data %>%
  mutate(
    Article = case_when(
      str_detect(Source, "^[^_]+_\\d{4}_[^_]+_Exp\\d+") ~ str_extract(Source, "^[^_]+_\\d{4}_[^_]+"),  # 发表的格式
      str_detect(Source, "^[^_]+_\\d{4}_Exp\\d+") ~ str_extract(Source, "^[^_]+_\\d{4}")  # 未发表的格式
    ),
    Experiment = str_extract(Source, "Exp\\d+"),  # 提取实验编号
    Subject_ID = str_extract(Subject, "[^_]+$")  # 提取被试编号
  )

# 统计文章、实验、被试数量
summary_table <- data %>%
  group_by(Article, Experiment) %>%
  summarise(Num_Subjects = n_distinct(Subject_ID), .groups = "drop") %>%
  arrange(Article, Experiment)

# 统计每篇文章的实验数
article_summary <- summary_table %>%
  group_by(Article) %>%
  summarise(Num_Experiments = n_distinct(Experiment), Total_Subjects = sum(Num_Subjects), .groups = "drop")

# 输出结果
write.csv(summary_table, "Experiment_Summary.csv", row.names = FALSE)
write.csv(article_summary, "Article_Summary.csv", row.names = FALSE)

# 打印摘要信息
print("实验统计完成，已输出以下文件：")
print("- Experiment_Summary.csv（每篇文章的实验及被试数量）")
print("- Article_Summary.csv（每篇文章的实验数和总被试数）")

```

## Pic1
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(Hmisc)
library(plyr)
library(RColorBrewer)
library(reshape2)

# 读取数据
data <- read.csv("Processed_Data.csv")

# 重新命名列以匹配需求
colnames(data) <- c("rt_self", "rt_close", "rt_stranger", "rt_non_person", "rt_acquaintance", 
                    "cohens_d_self_close", "cohens_d_self_stranger", "cohens_d_self_non_person", "cohens_d_self_acquaintance")

# 计算 RT 差值
data$SA_RT <- data$rt_self - data$rt_acquaintance
data$SC_RT <- data$rt_self - data$rt_close
data$SS_RT <- data$rt_self - data$rt_stranger
data$SN_RT <- data$rt_self - data$rt_non_person

# 定义 geom_flat_violin
"%||%" <- function(a, b) { if (!is.null(a)) a else b }

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

GeomFlatViolin <- ggproto("GeomFlatViolin", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            data %>%
              group_by(group) %>%
              mutate(ymin = min(y),
                     ymax = max(y),
                     xmin = x,
                     xmax = x + width / 2)
          },
          draw_group = function(data, panel_scales, coord) {
            data <- transform(data, xminv = x,
                              xmaxv = x + violinwidth * (xmax - x))
            newdata <- rbind(plyr::arrange(transform(data, x = xminv), y),
                             plyr::arrange(transform(data, x = xmaxv), -y))
            newdata <- rbind(newdata, newdata[1,])
            ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          draw_key = draw_key_polygon,
          default_aes = aes(weight = 1, colour = "grey20", fill = "white", size = 0.5,
                            alpha = NA, linetype = "solid"),
          required_aes = c("x", "y")
)

raincloud_theme <- theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16),
  axis.title.y = element_text(size = 16),
  axis.text = element_text(size = 14),
  axis.text.x = element_text(angle = 45, vjust = 0.5),
  legend.title = element_text(size = 16),
  legend.text = element_text(size = 16),
  legend.position = "right",
  plot.title = element_text(lineheight = .8, face = "bold", size = 16),
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  axis.line.x = element_line(colour = 'black', size = 0.5, linetype = 'solid'),
  axis.line.y = element_line(colour = 'black', size = 0.5, linetype = 'solid')
)

# 画图函数
generate_plot <- function(x_var, y_var, x_label, y_label, title) {
  ggplot(data, aes_string(x = x_var, y = y_var)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_boxplot(width = 0.2, outlier.shape = NA) +
    geom_flat_violin(aes(fill = ..density..), scale = "width", trim = FALSE, alpha = 0.5) +
    geom_smooth(method = "lm", color = "red", se = TRUE) +
    theme_minimal() +
    raincloud_theme +
    labs(x = x_label, y = y_label, title = title)
}

# 绘制四个图
p1.1 <- generate_plot("SA_RT", "cohens_d_self_acquaintance", "SA_RT", "Cohen's d (Self - Acquaintance)", "P1.1: RT vs. Cohen's d (Self - Acquaintance)")
p1.2 <- generate_plot("SC_RT", "cohens_d_self_close", "SC_RT", "Cohen's d (Self - Close)", "P1.2: RT vs. Cohen's d (Self - Close)")
p1.3 <- generate_plot("SS_RT", "cohens_d_self_stranger", "SS_RT", "Cohen's d (Self - Stranger)", "P1.3: RT vs. Cohen's d (Self - Stranger)")
p1.4 <- generate_plot("SN_RT", "cohens_d_self_non_person", "SN_RT", "Cohen's d (Self - Non-Person)", "P1.4: RT vs. Cohen's d (Self - Non-Person)")

# 显示所有图形
library(gridExtra)
grid.arrange(p1.1, p1.2, p1.3, p1.4, ncol = 2)
```

## Pic1_v2
```{r Package, warning = FALSE,message = FALSE}
# 加载必要的包
library(tidyverse)
library(effsize)      # 计算 Cohen's d
library(ggridges)     # 绘制 ridge plot
library(readr)

# 读取数据
df <- read_csv("Processed_Data.csv")
```

```{r}
# 筛选需要的 Identity 条件
identities <- c("Close", "Stranger", "Celebrity", "Acquaintance", "NonPerson")

# 创建空数据框保存 Cohen's d 结果
d_results <- data.frame()

# 循环每个 Identity 条件，计算对应的 Cohen's d 相对 Self
for (id in identities) {
  df_self <- df %>% filter(Standarlized_Identity == "Self")
  df_other <- df %>% filter(Standarlized_Identity == id)
  
  # inner join by Subject + Matching 以保证配对
  df_merged <- inner_join(
    df_self, df_other,
    by = c("Subject", "Matching"),
    suffix = c("_Self", "_Other")
  )
  
  # 计算 Cohen's d（配对样本）
  d_value <- cohen.d(
    df_merged$RT_ms_Self,
    df_merged$RT_ms_Other,
    paired = TRUE,
    hedges.correction = TRUE
  )$estimate
  
  # 保存结果
  d_results <- rbind(d_results, data.frame(Identity = id, Cohens_d = d_value))
}
```

```{r}
# 计算每个被试在每个 Identity 条件下与 Self 的 Cohen's d（近似方法）
all_d <- df %>%
  filter(Matching == "Matching") %>%
  filter(Standarlized_Identity %in% c("Self", identities)) %>%
  group_by(Subject, Matching, Standarlized_Identity) %>%
  summarise(RT_mean = mean(RT_ms), .groups = "drop") %>%
  pivot_wider(names_from = Standarlized_Identity, values_from = RT_mean) %>%
  rowwise() %>%
  mutate(
    d_Close = (Self - Close) / sd(c(Self, Close)),
    d_Stranger = (Self - Stranger) / sd(c(Self, Stranger)),
    d_Celebrity = (Self - Celebrity) / sd(c(Self, Celebrity)),
    d_Acquaintance = (Self - Acquaintance) / sd(c(Self, Acquaintance)),
    d_NonPerson = (Self - NonPerson) / sd(c(Self, NonPerson))
  ) %>%
  ungroup() %>%
  select(Subject, Matching, starts_with("d_")) %>%
  pivot_longer(
    cols = starts_with("d_"),
    names_to = "Identity",
    values_to = "Cohens_d"
  ) %>%
  mutate(Identity = str_remove(Identity, "d_"))
```

```{r}
ggplot(all_d, aes(x = Cohens_d, y = Identity, fill = Identity)) +
  geom_density_ridges(alpha = 0.7, scale = 1.2) +
  theme_ridges() +
  labs(
    title = "Distribution of Cohen's d (Self vs. Other Identities)",
    x = "Cohen's d (RT: Self - Other)",
    y = "Identity"
  ) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray30") +
  theme(legend.position = "none")

```

```{r}
ggplot(all_d, aes(x = Cohens_d, y = Identity, fill = Identity)) +
  geom_density_ridges(alpha = 0.7, scale = 1.2) +
  facet_wrap(~Matching) +
  theme_ridges() +
  labs(
    title = "Distribution of Cohen's d by Matching Condition",
    x = "Cohen's d (RT: Self - Other)",
    y = "Identity"
  ) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray30") +
  theme(legend.position = "none")
```

## Pic1_v3
```{r}
library(tidyverse)
library(ggridges)
library(effsize)

# 加载数据
df <- read_csv("Processed_Data.csv")

# 只保留 Matching 条件
df <- df %>% filter(Matching == "Matching")

# 比较用的 Identity（Self 为基准）
Identities <- c("Close", "Stranger", "Celebrity", "Acquaintance", "NonPerson")

# 计算每个 Source 下 Self vs. X 的 Cohen's d
cohen_d_by_source <- df %>%
  filter(Standarlized_Identity %in% c("Self", Identities)) %>%
  group_by(Source, Standarlized_Identity) %>%
  summarise(RT = list(as.numeric(RT_ms)), .groups = "drop") %>%
  pivot_wider(names_from = Standarlized_Identity, values_from = RT) %>%
  rowwise() %>%
  mutate(
    Cohens_d_Close = if (!is.null(Close) && !is.null(Self)) cohen.d(unlist(Self), unlist(Close), na.rm = TRUE)$estimate else NA,
    Cohens_d_Stranger = if (!is.null(Stranger) && !is.null(Self)) cohen.d(unlist(Self), unlist(Stranger), na.rm = TRUE)$estimate else NA,
    Cohens_d_Celebrity = if (!is.null(Celebrity) && !is.null(Self)) cohen.d(unlist(Self), unlist(Celebrity), na.rm = TRUE)$estimate else NA,
    Cohens_d_Acquaintance = if (!is.null(Acquaintance) && !is.null(Self)) cohen.d(unlist(Self), unlist(Acquaintance), na.rm = TRUE)$estimate else NA,
    Cohens_d_NonPerson = if (!is.null(NonPerson) && !is.null(Self)) cohen.d(unlist(Self), unlist(NonPerson), na.rm = TRUE)$estimate else NA
  ) %>%
  select(Source, starts_with("Cohens_d")) %>%
  pivot_longer(
    cols = starts_with("Cohens_d"),
    names_to = "Identity",
    values_to = "Cohens_d"
  ) %>%
  mutate(Identity = str_replace(Identity, "Cohens_d_", "")) %>%
  drop_na(Cohens_d)

# 绘制山脊图
ggplot(cohen_d_by_source, aes(x = Cohens_d, y = Identity, fill = Identity)) +
  geom_density_ridges(alpha = 0.8, scale = 1.2) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray40") +
  theme_ridges() +
  labs(
    title = "Distribution of Cohen's d (Self vs. Other) across Articles",
    x = "Cohen's d (RT: Self - Other)",
    y = "Identity"
  ) +
  theme(legend.position = "none")


```

## Pic1_v4








# Copute SDE
## Read csv (区分公开和未公开) [只包含有Trial记录的]
```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 需要排除的文件夹
# exclude_folders <- c("Bukowski_2021_AP", "Golubickis_2021_AP", 
#                      "Hobbs_2023_PM", "Mcivor_2020_EJN", 
#                      "Orellana-Corrales_2021_EP", "Svensson_2021_PR", 
#                      "Wang_2016_EPHPP","Liang_2022_HBM","Hobbs_2021_PM",
#                      "Lee_2023_Cognition","Orellana-Corrales_2021_APP",
#                      "Kirk_2025_BJP","Svensson_2023_QJEP")

## 过滤掉不需要的文件
data_files <- data_files[!grepl(paste(exclude_folders, collapse = "|"), data_files)]

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching", "Trial") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    # Data <- Data %>%
    #   filter(RT_ms > 10 & RT_ms < 5000, ACC %in% c(0, 1))  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Trial, Block, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data_for_SDE.csv", row.names = FALSE)
```

## [包含Block]
```{r}
library(dplyr)
library(readr)

## 设置数据路径
dataPath <- "../1_Clean_Data"
data_files <- list.files(path = dataPath, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

## 需要排除的文件夹
# exclude_folders <- c("Bukowski_2021_AP", "Golubickis_2021_AP", 
#                      "Hobbs_2023_PM", "Mcivor_2020_EJN", 
#                      "Orellana-Corrales_2021_EP", "Svensson_2021_PR", 
#                      "Wang_2016_EPHPP")

## 过滤掉不需要的文件
data_files <- data_files[!grepl(paste(exclude_folders, collapse = "|"), data_files)]

## 预分配存储变量（列表存储数据）
results_list <- list()

## 计数器
counter <- 1

## 读取 CSV 文件并处理数据
for (i in seq_along(data_files)) {
  file_name <- basename(data_files[i])  # 提取文件名（假设文件名代表文章名称）
  
  Data <- read_csv(data_files[i], show_col_types = FALSE) %>%
    mutate(across(where(is.character), as.character))  # 确保字符变量类型一致
  
  # 确保数据包含所需变量
  if (all(c("RT_ms", "ACC", "Standarlized_Identity", "Subject", "Matching", "Block", "Trial","Gender") %in% names(Data))) {
    
    # 生成唯一标识每篇文章的 Subject ID，并添加 Source 变量
    Data <- Data %>%
      mutate(
        Subject = paste0(file_name, "_", Subject),
        Source = file_name  # **新增变量，标记来源文章**
      )
    
    # 过滤 RT 在合理范围内的行
    # Data <- Data %>%
    #   filter(RT_ms > 10 & RT_ms < 5000, ACC %in% c(0, 1))  # 过滤异常值

    # **存入列表**
    results_list[[counter]] <- Data %>%
      select(Source, Subject, Block, Trial, Matching, Standarlized_Identity, RT_ms, ACC)  # **保留 Source 变量**
    
    counter <- counter + 1
  }
  print(paste('完成数据集', i, '处理'))
}

# **合并所有数据**
results <- bind_rows(results_list)

# **检查合并后的数据**
print("数据处理完成，已存入 `results` 变量")

# **输出数据到 CSV**
write.csv(results, "Processed_Data_for_SDE.csv", row.names = FALSE)
```


## Test01
```{r}
library(dplyr)
library(lme4)  # 用于LMM
library(lmerTest)  # 提供p值（可选）

# 假设你的数据已加载到 `results` 中
# 如果没有，先运行你的原始代码生成 `results`

# 1. 按Subject和Block排序，并生成lag变量
data_seq <- results %>%
  arrange(Subject, Block, Trial) %>%
  group_by(Subject, Block) %>%  # 在每个Subject和Block内操作
  mutate(
    Lag1_Identity = lag(Standarlized_Identity, 1),  # 前1次
    Lag2_Identity = lag(Standarlized_Identity, 2),  # 前2次
    Lag3_Identity = lag(Standarlized_Identity, 3),  # 前3次
    Lag4_Identity = lag(Standarlized_Identity, 4),  # 前4次
    Lag5_Identity = lag(Standarlized_Identity, 5),  # 前5次
    Lag6_Identity = lag(Standarlized_Identity, 6),  # 前6次
    Lag7_Identity = lag(Standarlized_Identity, 7)   # 前7次
  ) %>%
  ungroup()

# 2. 移除开头没有完整lag数据的行
data_seq_clean <- data_seq %>%
  filter(!is.na(Lag7_Identity))  # 确保所有lag变量都非NA

# 3. 检查数据
print("序列位置效应数据已生成，以下是前几行：")
print(head(data_seq_clean))

# 4. 建立LMM模型分析RT
# 固定效应：当前Identity + 前7次Identity
# 随机效应：Subject
rt_lmm <- lmer(RT_ms ~ Standarlized_Identity + Lag1_Identity + Lag2_Identity + 
               Lag3_Identity + Lag4_Identity + Lag5_Identity + Lag6_Identity + 
               Lag7_Identity + (1 | Subject), 
               data = data_seq_clean)

# 5. 查看模型结果
summary(rt_lmm)

# 6. （可选）保存模型结果到文件
sink("RT_LMM_Summary.txt")
print(summary(rt_lmm))
sink()

# 7. 保存处理后的数据
write.csv(data_seq_clean, "Sequence_Effect_Data.csv", row.names = FALSE)
```


## Test02
```{r}
# 加载必要的库
library(dplyr)
library(ggplot2)
library(readr)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 按 Source、Subject 和 Trial 排序
data <- data %>%
  arrange(Source, Subject, Trial) %>%
  group_by(Source, Subject) %>%
  mutate(
    Prev_Matching = lag(Matching),  # 计算上一试次的Matching
    Prev_ACC = lag(ACC),            # 计算上一试次的正确率
    Prev_RT_ms = lag(RT_ms)         # 计算上一试次的反应时
  ) %>%
  ungroup()

# 计算上一试次的Matching对当前试次ACC的影响
acc_model <- glm(ACC ~ Prev_Matching, data = data, family = binomial)
summary(acc_model)

# 计算上一试次的Matching对当前试次RT_ms的影响
rt_model <- lm(RT_ms ~ Prev_Matching, data = data)
summary(rt_model)

# 可视化上一试次Matching对当前试次RT_ms的影响
ggplot(data, aes(x = Prev_Matching, y = RT_ms)) +
  geom_boxplot() +
  labs(title = "Previous Matching Condition and Current RT_ms",
       x = "Previous Matching Condition",
       y = "Reaction Time (ms)") +
  theme_minimal()

```


## Test03（Result）
```{r}
# 加载必要的包
library(tidyverse)
library(lme4)
library(lmerTest)
library(ggplot2)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 按 Source（实验来源）、Subject（被试）、Trial（试次）排序，确保顺序正确
data <- data %>% arrange(Source, Subject, Trial)

# 计算 Lag-1 变量（上一试次的 Matching 条件）
data <- data %>%
  group_by(Source, Subject) %>%
  mutate(Prev_Matching = lag(Matching)) %>%
  ungroup()

# 移除首个试次（因为没有上一试次）
data <- na.omit(data)

# 清理 ACC：将 1 以外的所有值（包括 NA）统一处理为 0
data <- data %>%
  mutate(ACC = ifelse(ACC == 1, 1, 0))

# 确保 Matching 和 Prev_Matching 是因子变量
data$Matching <- as.factor(data$Matching)
data$Prev_Matching <- as.factor(data$Prev_Matching)

# 构建逻辑回归模型（因变量：ACC，预测变量：Prev_Matching）
acc_model <- glmer(ACC ~ Prev_Matching + (1 | Subject) + (1 | Source) + (1 | Block),
                   family = binomial, data = data)

# 输出模型摘要
summary(acc_model)

```

```{r}
# 逻辑回归模型（因变量：ACC，预测变量：Prev_Matching）
acc_model <- glmer(ACC ~ Prev_Matching + (1 | Subject) + (1 | Source) + (1 | Block),
                   family = binomial, data = data)

# 输出结果
summary(acc_model)
```

```{r}
# 计算不同 Lag（1~7） 条件下的相关系数
compute_autocorr <- function(data, max_lag = 7) {
  autocorr_results <- data.frame(Lag = integer(), Beta = numeric(), SE = numeric(), P_Value = numeric())
  
  for (lag in 1:max_lag) {
    data <- data %>%
      group_by(Source, Subject) %>%
      mutate(Prev_Matching = lag(Matching, lag)) %>%
      ungroup() %>%
      na.omit()
    
    # 计算混合模型
    model <- glmer(ACC ~ Prev_Matching + (1 | Subject) + (1 | Source) + (1 | Block), family = binomial, data = data)
    
    # 提取 β 系数、标准误和 p 值
    beta <- summary(model)$coefficients["Prev_MatchingNonmatching", "Estimate"]
    se <- summary(model)$coefficients["Prev_MatchingNonmatching", "Std. Error"]
    p_value <- summary(model)$coefficients["Prev_MatchingNonmatching", "Pr(>|z|)"]
    
    # 存储结果
    autocorr_results <- rbind(autocorr_results, data.frame(Lag = lag, Beta = beta, SE = se, P_Value = p_value))
  }
  
  return(autocorr_results)
}

# 计算 Lag-1 ~ Lag-7 的自相关
autocorr_results <- compute_autocorr(data, max_lag = 7)

# 查看结果
print(autocorr_results)
```

```{r}
# 画图（仿照 Rahnev 的 NHB 图）
ggplot(autocorr_results, aes(x = Lag, y = Beta)) +
  geom_point(size = 4, color = "blue") +                        # 画点
  geom_errorbar(aes(ymin = Beta - SE, ymax = Beta + SE),        # 误差条
                width = 0.2, color = "blue") +
  geom_line(size = 1, color = "blue") +                         # 连接线
  theme_minimal(base_size = 16) +
  labs(title = "Serial Dependence in Accuracy (Lag-1 to Lag-7)",
       x = "Lag (Previous Trial)",
       y = "Autocorrelation (Beta ± SEM)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```

```{r}
# 加载必要的包
library(tidyverse)
library(lme4)
library(lmerTest)
library(ggplot2)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 排序，确保时间顺序正确
data <- data %>% arrange(Source, Subject, Trial)

# 将 RT_ms 转换为数值（确保格式正确）
data$RT_ms <- as.numeric(data$RT_ms)

# 移除 RT 为空 或 小于 200ms / 大于 3000ms 的异常值（可选）
data <- data %>% filter(RT_ms >= 200 & RT_ms <= 3000)

# 确保 Matching 是因子变量
data$Matching <- as.factor(data$Matching)

# ====== 自定义函数：计算 RT 的序列位置效应 ======
compute_rt_autocorr <- function(data, max_lag = 7) {
  autocorr_results <- data.frame(Lag = integer(), Beta = numeric(), SE = numeric(), P_Value = numeric())
  
  for (lag in 1:max_lag) {
    data_lag <- data %>%
      group_by(Source, Subject) %>%
      mutate(Prev_Matching = lag(Matching, lag)) %>%
      ungroup() %>%
      drop_na(Prev_Matching, RT_ms)
    
    # 建立线性混合模型（LMM）
    model <- lmer(RT_ms ~ Prev_Matching + (1 | Subject) + (1 | Source) + (1 | Block), data = data_lag)
    
    # 提取 β 系数、标准误和 p 值（以 Prev_MatchingNonmatching 为参考）
    beta <- summary(model)$coefficients["Prev_MatchingNonmatching", "Estimate"]
    se <- summary(model)$coefficients["Prev_MatchingNonmatching", "Std. Error"]
    p_value <- summary(model)$coefficients["Prev_MatchingNonmatching", "Pr(>|t|)"]
    
    # 存储结果
    autocorr_results <- rbind(autocorr_results,
                              data.frame(Lag = lag, Beta = beta, SE = se, P_Value = p_value))
  }
  
  return(autocorr_results)
}

# 运行函数，计算 RT 的 Lag-1 ~ Lag-7 序列效应
rt_autocorr_results <- compute_rt_autocorr(data, max_lag = 7)

# 查看结果
print(rt_autocorr_results)

# ====== 可视化 Lag 的 RT 序列效应 ======
ggplot(rt_autocorr_results, aes(x = Lag, y = Beta)) +
  geom_point(size = 4, color = "darkred") +
  geom_errorbar(aes(ymin = Beta - SE, ymax = Beta + SE), width = 0.2, color = "darkred") +
  geom_line(size = 1, color = "darkred") +
  theme_minimal(base_size = 16) +
  labs(title = "Serial Dependence in RT (Lag-1 to Lag-7)",
       x = "Lag (Previous Trial)",
       y = "Effect of Prev_Matching on RT (Beta ± SEM)") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```


## Test04
```{r}
# 加载必要的包
library(tidyverse)
library(lme4)
library(lmerTest)
library(broom.mixed)

# 读取数据
data <- read_csv("Processed_Data_for_SDE.csv")

# 预处理：生成lag变量
data_preprocessed <- data %>%
  arrange(Source, Subject, Trial) %>%
  group_by(Subject) %>%
  mutate(
    Lag1_Matching = lag(Matching),
    Lag2_Matching = lag(Matching, 2),
    Lag3_Matching = lag(Matching, 3),
    Lag4_Matching = lag(Matching, 4),
    Lag5_Matching = lag(Matching, 5),
    Lag6_Matching = lag(Matching, 6),
    Lag7_Matching = lag(Matching, 7)
  ) %>%
  ungroup()

# 初始化结果存储
results <- tibble()

# 分析不同lag的效应
for (lag_num in 1:7) {
  # 选择对应的lag变量
  lag_var <- paste0("Lag", lag_num, "_Matching")
  
  # 过滤有效数据
  temp_data <- data_preprocessed %>%
    filter(!is.na(!!sym(lag_var))) %>%
    rename(Current_Matching = Matching)
  
  # 运行混合效应模型（以反应时为例）
  model <- lmer(
    RT_ms ~ !!sym(lag_var) + (1 | Subject) + (1 | Source),
    data = temp_data
  )
  
  # 提取结果
  summ <- summary(model)
  coeffs <- summ$coefficients
  
  # 存储结果
  results <- results %>% bind_rows(
    tibble(
      Lag = lag_num,
      Beta = coeffs[2, "Estimate"],
      SE = coeffs[2, "Std. Error"],
      t = coeffs[2, "t value"],
      p = coeffs[2, "Pr(>|t|)"]
    )
  )
}

# 可视化
ggplot(results, aes(x = Lag, y = Beta)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray60") +
  geom_line(color = "steelblue") +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbar(aes(ymin = Beta - SE, ymax = Beta + SE), 
                width = 0.2, color = "steelblue") +
  geom_text(aes(label = ifelse(p < 0.001, "***", 
                             ifelse(p < 0.01, "**",
                                    ifelse(p < 0.05, "*", "")))),
            vjust = -0.5, size = 5) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Lag", 
       y = "β Coefficient",
       title = "Serial Dependence in Reaction Time",
       subtitle = "Effect of Previous Trial's Matching Condition on Current Trial RT") +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )
```


## Test05
```{r}
library(tidyverse)
library(lme4)
library(data.table)
library(lmerTest) 

# 读取数据
df <- read.csv("Processed_Data_for_SDE.csv")

# 转换变量类型
df <- df %>%
  mutate(
    Subject = as.factor(Subject),
    Source = as.factor(Source),
    Matching = as.factor(Matching),
    Standarlized_Identity = as.factor(Standarlized_Identity)
  ) %>%
  arrange(Subject, Trial)  # 按照被试 & 试次顺序排序

```

```{r}
# 使用 data.table 加速滞后变量生成
df_dt <- as.data.table(df)

# 对每个被试分别生成滞后 RT_ms 变量
for (i in 1:7) {
  df_dt[, paste0("RT_ms_n", i) := shift(RT_ms, n = i, type = "lag"), by = Subject]
}

```

```{r}
#删除前7行缺失（由于滞后变量导致）
df_clean <- df_dt %>% drop_na(RT_ms_n1, RT_ms_n2, RT_ms_n3, RT_ms_n4, RT_ms_n5, RT_ms_n6, RT_ms_n7)
```

```{r}
# 构建混合效应模型：当前RT受前1~7个RT影响
fit <- lmer(RT_ms ~ RT_ms_n1 + RT_ms_n2 + RT_ms_n3 + RT_ms_n4 + RT_ms_n5 + RT_ms_n6 + RT_ms_n7 + (1 | Subject) + (1 | Source) + (1 | Block), 
            data = df_clean)


coef_summary <- as.data.frame(coef(summary(fit)))
coef_summary$p_value <- 2 * (1 - pnorm(abs(coef_summary$"t value")))
print(coef_summary)
summary(fit)
```

```{r}
# 提取固定效应并画图
tmp <- as.data.frame(confint(fit))
tmp <- tmp[grep("RT_ms_n", rownames(tmp)), ]
tmp$Estimate <- fixef(fit)[grep("RT_ms_n", names(fixef(fit)))]
tmp$lwr <- tmp$`2.5 %`
tmp$upr <- tmp$`97.5 %`
tmp$History <- paste0("RT n-", 1:7)

# 可视化
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
  geom_point(size = 3) +
  geom_errorbar(width = 0.2) +
  theme_minimal() +
  labs(title = "Serial Dependence of RT (n-1 to n-7)",
       x = "Lagged RT",
       y = "Effect on Current RT")

```

## Test06（Good Fit)
### RT
```{r}
library(tidyverse)
library(lme4)
library(data.table)

# 读取数据
df <- read_csv("Processed_Data_for_SDE.csv")
# 转换变量类型
df <- df %>%
  mutate(
    Subject = as.factor(Subject),
    Block = as.factor(Block),
    Trial = as.factor(Trial),
    Source = as.factor(Source),
    Matching = as.factor(Matching),
    Standarlized_Identity = as.factor(Standarlized_Identity)
    
  ) %>%
  arrange(Subject, Block, Trial)  # 按照被试 & 试次顺序排序

```

### log7
```{r}
# 使用 data.table 加速滞后变量生成
df_dt <- as.data.table(df)

# 对每个被试分别生成滞后 RT_ms 变量
for (i in 1:7) {
  df_dt[, paste0("RT_ms_n", i) := shift(RT_ms, n = i, type = "lag"), by = Subject]
}

```

```{r}
#删除前7行缺失（由于滞后变量导致）
df_clean <- df_dt %>% drop_na(RT_ms_n1, RT_ms_n2, RT_ms_n3, RT_ms_n4, RT_ms_n5, RT_ms_n6, RT_ms_n7)
```

```{r}
# 构建混合效应模型：当前RT受前1~7个RT影响
fit <- lmer(RT_ms ~ RT_ms_n1 + RT_ms_n2 + RT_ms_n3 + RT_ms_n4 + RT_ms_n5 + RT_ms_n6 + RT_ms_n7 + (1 | Source)+ (1 | Subject) + (1 | Block), 
            data = df_clean)

coef_summary <- as.data.frame(coef(summary(fit)))
coef_summary$p_value <- 2 * (1 - pnorm(abs(coef_summary$"t value")))
print(coef_summary)
summary(fit)
```

```{r}
# 提取固定效应并画图
tmp <- as.data.frame(confint(fit))
tmp <- tmp[grep("RT_ms_n", rownames(tmp)), ]
tmp$Estimate <- fixef(fit)[grep("RT_ms_n", names(fixef(fit)))]
tmp$lwr <- tmp$`2.5 %`
tmp$upr <- tmp$`97.5 %`
tmp$History <- paste0("RT n-", 1:7)

# 可视化
ggplot(tmp, aes(x = History, y = Estimate, ymin = lwr, ymax = upr)) +
  geom_point(size = 3) +
  geom_errorbar(width = 0.2) +
  theme_minimal() +
  labs(title = "Serial Dependence of RT (n-1 to n-7)",
       x = "Lagged RT",
       y = "Effect on Current RT")

```



## Test_Age log?
```{r}
# 加载必要的包
library(tidyverse)
library(e1071)      # 用于 skewness
library(ggplot2)    # 可视化
library(ggpubr)     # QQ图
library(readr)      # 读取CSV

# 读取数据
data_v1 <- read_csv("../3_Code/Processed_Data_by_age&gender.csv")

  # 查看前几行
head(data_v1)

# 绘制直方图
ggplot(data_v1, aes(x = RT_ms)) +
  geom_histogram(bins = 50, fill = "steelblue", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of RT_ms")

# 强制转换为数值（非数值将变成 NA）
data_v1$RT_ms <- as.numeric(data_v1$RT_ms)

# 偏度
skew_val <- skewness(data$RT_ms, na.rm = TRUE)
cat("Skewness of RT_ms:", skew_val, "\n")


```

```{r}
# 添加 log 变量
data_v1$log_RT_ms <- log(data_v1$RT_ms)

# 检查分布
ggplot(data_v1, aes(x = log_RT_ms)) +
  geom_histogram(bins = 50, fill = "darkgreen", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of log(RT_ms)")

# 计算 log 后偏度
library(e1071)
skewness(data_v1$log_RT_ms, na.rm = TRUE)

```

```{r}
# 加载必要的包
library(tidyverse)
library(e1071)      # 用于 skewness
library(ggplot2)    # 可视化
library(ggpubr)     # QQ图
library(readr)      # 读取CSV

# 读取数据
data_v1 <- read_csv("../3_Code/Processed_Data_by_age&gender.csv")

  # 查看前几行
head(data_v1)

# 绘制直方图
ggplot(data_v1, aes(x = Age)) +
  geom_histogram(bins = 50, fill = "steelblue", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Age")

# 强制转换为数值（非数值将变成 NA）
data_v1$RT_ms <- as.numeric(data_v1$RT_ms)

# 偏度
skew_val <- skewness(data$Age, na.rm = TRUE)
cat("Skewness of RT_ms:", skew_val, "\n")


```


```{r}
library(dplyr)
library(effsize)
library(ggplot2)
library(readr)
library(tidyr)

# 读取并筛选 Nonmatching 条件
data <- read_csv("../3_Code/Processed_Data_Filtered_with_logRT.csv", show_col_types = FALSE)

data_filtered <- data %>%
  filter(Matching == "Nonmatching", Standarlized_Identity %in% c("Self", "Stranger"))

# 获取唯一被试并打乱顺序
set.seed(42)
all_subjects <- unique(data_filtered$Subject)
shuffled_subjects <- sample(all_subjects)

# 设定每步的样本量
sample_sizes <- seq(60, length(shuffled_subjects), by = 40)

# 初始化结果存储
result_df <- data.frame(SampleSize = integer(), Cohens_d = numeric())

# 循环逐步增加样本量计算效应量
for (n in sample_sizes) {
  selected_subjects <- shuffled_subjects[1:n]
  sample_data <- data_filtered %>%
    filter(Subject %in% selected_subjects)

  summary_data <- sample_data %>%
    group_by(Subject, Standarlized_Identity) %>%
    summarise(MeanRT = mean(RT_ms, na.rm = TRUE), .groups = "drop") %>%
    pivot_wider(names_from = Standarlized_Identity, values_from = MeanRT)

  if (all(c("Self", "Stranger") %in% colnames(summary_data))) {
    temp <- summary_data %>% filter(!is.na(Self) & !is.na(Stranger))
    if (nrow(temp) >= 2) {
      d <- cohen.d(temp$Self, temp$Stranger, paired = TRUE)$estimate
      result_df <- rbind(result_df, data.frame(SampleSize = n, Cohens_d = d))
    }
  }
}


# 绘制样本量 vs Cohen's d 的折线图
ggplot(result_df, aes(x = SampleSize, y = Cohens_d)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "darkred", size = 2) +
  theme_minimal() +
  labs(title = "SPE效应量随样本量变化（Cohen's d, Nonmatching）",
       x = "样本量（被试数）", y = "效应量 Cohen's d")
```


```{r}
library(dplyr)
library(effsize)
library(ggplot2)
library(readr)
library(tidyr)

# 读取并筛选 Nonmatching 条件
data <- read_csv("../3_Code/Processed_Data_Filtered_with_logRT.csv", show_col_types = FALSE)

data_filtered <- data %>%
  filter(Matching == "Nonmatching", Standarlized_Identity %in% c("Self", "Close"))

# 获取唯一被试并打乱顺序
set.seed(42)
all_subjects <- unique(data_filtered$Subject)
shuffled_subjects <- sample(all_subjects)

# 设定每步的样本量
sample_sizes <- seq(60, length(shuffled_subjects), by = 10)

# 初始化结果存储
result_df <- data.frame(SampleSize = integer(), Cohens_d = numeric())

# 循环逐步增加样本量计算效应量
for (n in sample_sizes) {
  selected_subjects <- shuffled_subjects[1:n]
  sample_data <- data_filtered %>%
    filter(Subject %in% selected_subjects)

  summary_data <- sample_data %>%
    group_by(Subject, Standarlized_Identity) %>%
    summarise(MeanRT = mean(RT_ms, na.rm = TRUE), .groups = "drop") %>%
    pivot_wider(names_from = Standarlized_Identity, values_from = MeanRT)

  if (all(c("Self", "Close") %in% colnames(summary_data))) {
    temp <- summary_data %>% filter(!is.na(Self) & !is.na(Close))
    if (nrow(temp) >= 2) {
      d <- cohen.d(temp$Self, temp$Close, paired = TRUE)$estimate
      result_df <- rbind(result_df, data.frame(SampleSize = n, Cohens_d = d))
    }
  }
}


# 绘制样本量 vs Cohen's d 的折线图
ggplot(result_df, aes(x = SampleSize, y = Cohens_d)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "darkred", size = 2) +
  theme_minimal() +
  labs(title = "SPE效应量随样本量变化（Cohen's d, Nonmatching）",
       x = "样本量（被试数）", y = "效应量 Cohen's d")
```



